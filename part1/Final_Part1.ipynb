{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3496c14",
   "metadata": {},
   "source": [
    "# Project Part 1\n",
    "**Eliya Zaguri ID 207313131**\n",
    "\n",
    "[GitHub Repository](https://github.com/eliyazaguri/car-price-prediction-project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5cb8415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 48 car links.\n",
      "Scraping data from https://www.ad.co.il/ad/16183484\n",
      "Scraping data from https://www.ad.co.il/ad/16093061\n",
      "Scraping data from https://www.ad.co.il/ad/16053968\n",
      "Scraping data from https://www.ad.co.il/ad/16053457\n",
      "Scraping data from https://www.ad.co.il/ad/16040471\n",
      "Scraping data from https://www.ad.co.il/ad/15943965\n",
      "Scraping data from https://www.ad.co.il/ad/15512048\n",
      "Scraping data from https://www.ad.co.il/ad/15781247\n",
      "Scraping data from https://www.ad.co.il/ad/15512138\n",
      "Scraping data from https://www.ad.co.il/ad/15742382\n",
      "Scraping data from https://www.ad.co.il/ad/15371056\n",
      "Scraping data from https://www.ad.co.il/ad/14928292\n",
      "Scraping data from https://www.ad.co.il/ad/14760739\n",
      "Scraping data from https://www.ad.co.il/ad/14668072\n",
      "Scraping data from https://www.ad.co.il/ad/14655334\n",
      "Scraping data from https://www.ad.co.il/ad/14651769\n",
      "Scraping data from https://www.ad.co.il/ad/14611346\n",
      "Scraping data from https://www.ad.co.il/ad/14599028\n",
      "Scraping data from https://www.ad.co.il/ad/14583213\n",
      "Scraping data from https://www.ad.co.il/ad/14570578\n",
      "Scraping data from https://www.ad.co.il/ad/14559795\n",
      "Scraping data from https://www.ad.co.il/ad/14559803\n",
      "Scraping data from https://www.ad.co.il/ad/14514809\n",
      "Scraping data from https://www.ad.co.il/ad/14481317\n",
      "Scraping data from https://www.ad.co.il/ad/14469300\n",
      "Scraping data from https://www.ad.co.il/ad/14466106\n",
      "Scraping data from https://www.ad.co.il/ad/14430563\n",
      "Scraping data from https://www.ad.co.il/ad/14355648\n",
      "Scraping data from https://www.ad.co.il/ad/14329631\n",
      "Scraping data from https://www.ad.co.il/ad/14329625\n",
      "Scraping data from https://www.ad.co.il/ad/14320682\n",
      "Scraping data from https://www.ad.co.il/ad/14264312\n",
      "Scraping data from https://www.ad.co.il/ad/14192175\n",
      "Scraping data from https://www.ad.co.il/ad/14177731\n",
      "Scraping data from https://www.ad.co.il/ad/14165565\n",
      "Scraping data from https://www.ad.co.il/ad/14145409\n",
      "Scraping data from https://www.ad.co.il/ad/14022629\n",
      "Scraping data from https://www.ad.co.il/ad/13992775\n",
      "Scraping data from https://www.ad.co.il/ad/13984115\n",
      "Scraping data from https://www.ad.co.il/ad/13710158\n",
      "Scraping data from https://www.ad.co.il/ad/13664856\n",
      "Scraping data from https://www.ad.co.il/ad/13149153\n",
      "Scraping data from https://www.ad.co.il/ad/13047128\n",
      "Scraping data from https://www.ad.co.il/ad/15903508\n",
      "Scraping data from https://www.ad.co.il/ad/14664065\n",
      "Scraping data from https://www.ad.co.il/ad/14489926\n",
      "Scraping data from https://www.ad.co.il/ad/14380441\n",
      "Scraping data from https://www.ad.co.il/ad/14272363\n",
      "Data scraped and saved to cleaned_car_data.csv\n"
     ]
    }
   ],
   "source": [
    "# שלב 1: יבוא הספריות הנדרשות\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# שלב 2: פונקציה לקבלת תוכן ה-HTML של הדף\n",
    "def get_html(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        response.encoding = 'utf-8'  # Ensure correct encoding\n",
    "        return response.text\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# שלב 3: פונקציה לאיסוף הנתונים מהדף הראשי\n",
    "def scrape_main_page_data(card):\n",
    "    data = {}\n",
    "    data['יצרן'] = 'פיאט'  # אנו מניחים שהיצרן הוא תמיד פיאט במודעה זו\n",
    "    title = card.find('h2', class_='card-title').text.strip() if card.find('h2', class_='card-title') else 'N/A'\n",
    "    if title.startswith('פיאט'):\n",
    "        data['דגם'] = title.replace('פיאט', '').strip()\n",
    "    else:\n",
    "        data['דגם'] = 'N/A'\n",
    "    data['מחיר'] = card.find('div', class_='price').text.strip() if card.find('div', class_='price') else 'N/A'\n",
    "    data['אזור'] = card.find('span', class_='region').text.strip() if card.find('span', class_='region') else 'N/A'\n",
    "    data['עיר'] = card.find('span', class_='city').text.strip() if card.find('span', 'city') else 'N/A'\n",
    "    return data\n",
    "\n",
    "# שלב 4: פונקציה לאיסוף הנתונים מהטבלה בדף המודעה\n",
    "def scrape_car_data(car_soup, main_page_data):\n",
    "    data = main_page_data.copy()\n",
    "    table = car_soup.find('table', {'class': 'table table-sm mb-4'})\n",
    "    if not table:\n",
    "        print(\"No table found on page.\")\n",
    "        return data\n",
    "    \n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows:\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) == 2:\n",
    "            key = cols[0].text.strip()\n",
    "            value = cols[1].text.strip()\n",
    "            data[key] = value\n",
    "\n",
    "    # איסוף מידע נוסף לפי הדרישות\n",
    "    info_div = car_soup.find('div', class_='d-flex flex-row align-items-center justify-content-center flex-wrap')\n",
    "    if info_div:\n",
    "        creation_date_div = info_div.find_all('div', class_='px-3')\n",
    "        if len(creation_date_div) >= 2:\n",
    "            creation_date = creation_date_div[0].text.strip().split(': ')[-1]\n",
    "            repub_date = creation_date_div[1].text.strip().split(': ')[-1]\n",
    "            data['תאריך יצירה'] = pd.to_datetime(creation_date, dayfirst=True).strftime('%Y-%m-%d')\n",
    "            data['תאריך הקפצה'] = pd.to_datetime(repub_date, dayfirst=True).strftime('%Y-%m-%d')\n",
    "        else:\n",
    "            data['תאריך יצירה'] = 'N/A'\n",
    "            data['תאריך הקפצה'] = 'N/A'\n",
    "    else:\n",
    "        data['תאריך יצירה'] = 'N/A'\n",
    "        data['תאריך הקפצה'] = 'N/A'\n",
    "    \n",
    "    description = car_soup.find('p', class_='text-word-break')\n",
    "    if description:\n",
    "        data['תיאור'] = description.text.strip()\n",
    "    else:\n",
    "        data['תיאור'] = 'N/A'\n",
    "    \n",
    "    # מציאת מספר התמונות\n",
    "    images_wrapper = car_soup.find('div', class_='swiper-wrapper')\n",
    "    if images_wrapper:\n",
    "        image_slides = images_wrapper.find_all('div', class_='swiper-slide')\n",
    "        data['מספר תמונות'] = len(image_slides)\n",
    "    else:\n",
    "        data['מספר תמונות'] = 0\n",
    "\n",
    "    return data\n",
    "\n",
    "# שלב 5: פונקציה לאיסוף הקישורים למודעות מהרשימה הראשית\n",
    "def get_car_links(url):\n",
    "    html = get_html(url)\n",
    "    if not html:\n",
    "        return []\n",
    "\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    links = []\n",
    "    main_page_data_list = []\n",
    "\n",
    "    for card in soup.find_all('div', class_='card-body p-md-3'):\n",
    "        a = card.find('a', href=True)\n",
    "        if a:\n",
    "            href = a['href']\n",
    "            if href.startswith('/ad/'):\n",
    "                full_link = 'https://www.ad.co.il' + href\n",
    "                if 'פיאט' in card.text:\n",
    "                    links.append(full_link)\n",
    "                    main_page_data_list.append(scrape_main_page_data(card))\n",
    "\n",
    "    return links, main_page_data_list\n",
    "\n",
    "# שלב 6: פונקציה מרכזית לאיסוף הנתונים מכל המודעות בדף\n",
    "def scrape_all_cars(start_url):\n",
    "    car_links, main_page_data_list = get_car_links(start_url)\n",
    "    print(f\"Found {len(car_links)} car links.\")\n",
    "    \n",
    "    car_data = []\n",
    "\n",
    "    for link, main_page_data in zip(car_links, main_page_data_list):\n",
    "        print(f\"Scraping data from {link}\")\n",
    "        car_html = get_html(link)\n",
    "        if not car_html:\n",
    "            print(f\"Failed to retrieve {link}\")\n",
    "            continue\n",
    "\n",
    "        car_soup = BeautifulSoup(car_html, 'html.parser')\n",
    "        data = scrape_car_data(car_soup, main_page_data)\n",
    "        if data:\n",
    "            car_data.append(data)\n",
    "\n",
    "    return car_data\n",
    "\n",
    "# שלב 7: פונקציה לניקוי תיאורים ותיקון תווים\n",
    "def clean_description(desc):\n",
    "    if pd.isna(desc):\n",
    "        return desc\n",
    "    return ' '.join(desc.split())\n",
    "\n",
    "# שלב 8: דוגמה לשימוש בפונקציה לאיסוף הנתונים ושמירתם\n",
    "start_url = 'https://www.ad.co.il/car?sp261=13902'\n",
    "car_data = scrape_all_cars(start_url)\n",
    "\n",
    "# המרת הנתונים לפורמט DataFrame של pandas\n",
    "df = pd.DataFrame(car_data)\n",
    "\n",
    "# שלב 9: הגדרת כל העמודות הנדרשות, והוספת עמודות חסרות במידת הצורך\n",
    "required_columns = [\n",
    "    'יצרן', 'דגם', 'מחיר', 'אזור', 'עיר', 'שנה', 'יד', 'ת. הילוכים', 'נפח', 'סוג מנוע', \n",
    "    'בעלות קודמת', 'בעלות נוכחית', 'טסט עד', 'ק\"מ', 'צבע', 'תיאור', 'מספר תמונות', 'תאריך יצירה', 'תאריך הקפצה'\n",
    "]\n",
    "for col in required_columns:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 'N/A'\n",
    "\n",
    "# אם יש עמודות כפולות של \"טסט\" ו-\"טסט עד\", נוודא שמאחדים אותן\n",
    "if 'טסט עד' in df.columns and 'טסט' in df.columns:\n",
    "    df['טסט עד'] = df['טסט עד'].combine_first(df['טסט'])\n",
    "    df = df.drop(columns=['טסט'])\n",
    "\n",
    "# ניקוי כל העמודות מתווים לא תקינים ורווחים מיותרים\n",
    "for col in df.columns:\n",
    "    df[col] = df[col].apply(lambda x: x.strip() if isinstance(x, str) else x)\n",
    "\n",
    "# ניקוי התיאור\n",
    "df['תיאור'] = df['תיאור'].apply(clean_description)\n",
    "\n",
    "# שלב 10: שמירת הנתונים המעודכנים לקובץ CSV חדש\n",
    "df.to_csv('cleaned_car_data.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Data scraped and saved to cleaned_car_data.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
